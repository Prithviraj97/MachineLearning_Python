{"cells":[{"cell_type":"markdown","id":"prostate-arizona","metadata":{"id":"bA5ajAmk7XH6"},"source":["# Unsupervised Learning in Python\n","\n","Run the hidden code cell below to import the data used in this course."]},{"cell_type":"code","execution_count":null,"id":"2e25fdd8-4d84-45bc-80f0-949917e00a17","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"outputs":[],"source":["# Import the course packages\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","import scipy.stats \n","\n","# Import the course datasets \n","grains = pd.read_csv('datasets/grains.csv')\n","fish = pd.read_csv('datasets/fish.csv', header=None)\n","wine = pd.read_csv('datasets/wine.csv')\n","eurovision = pd.read_csv('datasets/eurovision-2016.csv')\n","stocks = pd.read_csv('datasets/company-stock-movements-2010-2015-incl.csv', index_col=0)\n","digits = pd.read_csv('datasets/lcd-digits.csv', header=None)"]},{"cell_type":"markdown","id":"a68ada23","metadata":{},"source":["## Take Notes\n","\n","Add notes about the concepts you've learned and code cells with code you want to keep."]},{"cell_type":"markdown","id":"ccb9c4ad","metadata":{},"source":["_Add your notes here_"]},{"cell_type":"code","execution_count":null,"id":"2fb68042","metadata":{},"outputs":[],"source":["# Add your code snippets here"]},{"cell_type":"markdown","id":"fiscal-syntax","metadata":{},"source":["## Explore Datasets\n","Use the DataFrames imported in the first cell to explore the data and practice your skills!\n","- You work for an agricultural research center. Your manager wants you to group seed varieties based on different measurements contained in the `grains` DataFrame. They also want to know how your clustering solution compares to the seed types listed in the dataset (the `variety_number` and `variety` columns). Try to use all of the relevant techniques you learned in Unsupervised Learning in Python!\n","- In the `fish` DataFrame, each row represents an individual fish. Standardize the features and cluster the fish by their measurements. You can then compare your cluster labels with the actual fish species (first column).\n","- In the `wine` DataFrame, there are three `class_labels` in this dataset. Transform the features to get the most accurate clustering.\n","- In the `eurovision` DataFrame, perform hierarchical clustering of the voting countries using `complete` linkage and plot the resulting dendrogram."]},{"cell_type":"code","execution_count":null,"id":"3f54c1b4-911f-4851-9b4c-2802ff9f3198","metadata":{},"outputs":[],"source":["# Import pyplot\n","import matplotlib.pyplot as plt\n","\n","# Assign the columns of new_points: xs and ys\n","xs = new_points[:,0]\n","ys = new_points[:,1]\n","\n","# Make a scatter plot of xs and ys, using labels to define the colors\n","plt.scatter(xs, ys, c=labels, alpha=0.5)\n","\n","# Assign the cluster centers: centroids\n","centroids = model.cluster_centers_\n","\n","# Assign the columns of centroids: centroids_x, centroids_y\n","centroids_x = centroids[:,0]\n","centroids_y = centroids[:,1]\n","\n","# Make a scatter plot of centroids_x and centroids_y\n","plt.scatter(centroids_x, centroids_y, marker='D', s=50)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"1efd7eb4-c49b-4add-a648-2d811357a1a7","metadata":{},"outputs":[],"source":["ks = range(1, 6)\n","inertias = []\n","\n","for k in ks:\n","    # Create a KMeans instance with k clusters: model\n","    model = KMeans(n_clusters=k)\n","    \n","    # Fit model to samples\n","    model.fit(samples)\n","    \n","    # Append the inertia to the list of inertias\n","    inertias.append(model.inertia_)\n","    \n","# Plot ks vs inertias\n","plt.plot(ks, inertias, '-o')\n","plt.xlabel('number of clusters, k')\n","plt.ylabel('inertia')\n","plt.xticks(ks)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"1c307451-c01e-4765-ae5a-d870aa3094ec","metadata":{},"outputs":[],"source":["# Create a KMeans model with 3 clusters: model\n","model = KMeans(n_clusters=3)\n","\n","# Use fit_predict to fit model and obtain cluster labels: labels\n","labels = model.fit_predict(samples)\n","\n","# Create a DataFrame with labels and varieties as columns: df\n","df = pd.DataFrame({'labels': labels, 'varieties': varieties})\n","\n","# Create crosstab: ct\n","ct = pd.crosstab(df['labels'], df['varieties'])\n","\n","# Display ct\n","print(ct)\n"]},{"cell_type":"code","execution_count":null,"id":"78d089ee-256e-461a-b98b-c8106e3954dc","metadata":{},"outputs":[],"source":["# Perform the necessary imports\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import make_pipeline\n","\n","# Create scaler: scaler\n","scaler = StandardScaler()\n","\n","# Create KMeans instance: kmeans\n","kmeans = KMeans(n_clusters=4)\n","\n","# Create pipeline: pipeline\n","pipeline = make_pipeline(scaler, kmeans)\n","\n","# Import pandas\n","import pandas as pd\n","\n","# Fit the pipeline to samples\n","pipeline.fit(samples)\n","\n","# Calculate the cluster labels: labels\n","labels = pipeline.predict(samples)\n","\n","# Create a DataFrame with labels and species as columns: df\n","df = pd.DataFrame({'labels':labels, 'species':species})\n","\n","# Create crosstab: ct\n","ct = pd.crosstab(df['labels'], df['species'])\n","\n","# Display ct\n","print(ct)\n"]},{"cell_type":"code","execution_count":null,"id":"8a9c2afb-71e7-486c-af3e-3ac2b394ee08","metadata":{},"outputs":[],"source":["# Import Normalizer\n","from sklearn.preprocessing import Normalizer\n","\n","# Create a normalizer: normalizer\n","normalizer = Normalizer()\n","\n","# Create a KMeans model with 10 clusters: kmeans\n","kmeans = KMeans(n_clusters=10)\n","\n","# Make a pipeline chaining normalizer and kmeans: pipeline\n","pipeline = make_pipeline(normalizer,kmeans)\n","\n","# Fit pipeline to the daily price movements\n","pipeline.fit(movements)\n","\n","# Import pandas\n","import pandas as pd\n","\n","# Predict the cluster labels: labels\n","labels = pipeline.predict(movements)\n","\n","# Create a DataFrame aligning labels and companies: df\n","df = pd.DataFrame({'labels': labels, 'companies': companies})\n","\n","# Display df sorted by cluster label\n","print(df.sort_values('labels'))\n"]},{"cell_type":"code","execution_count":null,"id":"d900d18b-0fad-4f19-bd26-bf8ed846a115","metadata":{},"outputs":[],"source":["'''Hierarchical clustering of the grain data\n","In the video, you learned that the SciPy linkage() function performs hierarchical clustering on an array of samples. Use the linkage() function to obtain a hierarchical clustering of the grain samples, and use dendrogram() to visualize the result. A sample of the grain measurements is provided in the array samples, while the variety of each grain sample is given by the list varieties.'''\n","# Perform the necessary imports\n","from scipy.cluster.hierarchy import linkage, dendrogram\n","import matplotlib.pyplot as plt\n","\n","# Calculate the linkage: mergings\n","mergings = linkage(samples, method='complete')\n","\n","# Plot the dendrogram, using varieties as labels\n","dendrogram(mergings,\n","           labels=varieties,\n","           leaf_rotation=90,\n","           leaf_font_size=6,\n",")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"bb2982c0-8e0b-4714-af29-3d1e32b71c22","metadata":{},"outputs":[],"source":["# Import normalize\n","from sklearn.preprocessing import normalize\n","\n","# Normalize the movements: normalized_movements\n","normalized_movements = normalize(movements)\n","\n","# Calculate the linkage: mergings\n","mergings = linkage(normalized_movements, method='complete')\n","\n","# Plot the dendrogram\n","dendrogram(mergings, labels=companies, leaf_rotation=90, leaf_font_size=6)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"9204eede-f951-4a3c-8a60-c4fc70e45589","metadata":{},"outputs":[],"source":["# Perform the necessary imports\n","import matplotlib.pyplot as plt\n","from scipy.cluster.hierarchy import linkage, dendrogram\n","\n","# Calculate the linkage: mergings\n","mergings = linkage(samples, method='single')\n","\n","# Plot the dendrogram\n","dendrogram(mergings, labels=country_names, leaf_rotation=90, leaf_font_size=6)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"cc243141-11d8-440e-bf32-5885903143cb","metadata":{},"outputs":[],"source":["# Perform the necessary imports\n","import pandas as pd\n","from scipy.cluster.hierarchy import fcluster\n","\n","# Use fcluster to extract labels: labels\n","labels = fcluster(mergings, 6, criterion='distance')\n","\n","# Create a DataFrame with labels and varieties as columns: df\n","df = pd.DataFrame({'labels': labels, 'varieties': varieties})\n","\n","# Create crosstab: ct\n","ct = pd.crosstab(df['labels'], df['varieties'])\n","\n","# Display ct\n","print(ct)\n"]},{"cell_type":"code","execution_count":null,"id":"2531f039-e310-40d5-b4c5-40a13f63f228","metadata":{},"outputs":[],"source":["# Import TSNE\n","from sklearn.manifold import TSNE\n","\n","# Create a TSNE instance: model\n","model = TSNE(learning_rate=200)\n","\n","# Apply fit_transform to samples: tsne_features\n","tsne_features = model.fit_transform(samples)\n","\n","# Select the 0th feature: xs\n","xs = tsne_features[:,0]\n","\n","# Select the 1st feature: ys\n","ys = tsne_features[:,1]\n","\n","# Scatter plot, coloring by variety_numbers\n","plt.scatter(xs, ys, c=variety_numbers)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"dbb6ca2b-f510-4c39-81c6-54849c75afda","metadata":{},"outputs":[],"source":["'''A t-SNE map of the stock market\n","t-SNE provides great visualizations when the individual samples can be labeled. In this exercise, you'll apply t-SNE to the company stock price data. A scatter plot of the resulting t-SNE features, labeled by the company names, gives you a map of the stock market! The stock price movements for each company are available as the array normalized_movements (these have already been normalized for you). The list companies gives the name of each company. PyPlot (plt) has been imported for you.'''\n","# Import TSNE\n","from sklearn.manifold import TSNE\n","\n","# Create a TSNE instance: model\n","model = TSNE(learning_rate=50)\n","\n","# Apply fit_transform to normalized_movements: tsne_features\n","tsne_features = model.fit_transform(normalized_movements)\n","\n","# Select the 0th feature: xs\n","xs = tsne_features[:,0]\n","\n","# Select the 1th feature: ys\n","ys = tsne_features[:,1]\n","\n","# Scatter plot\n","plt.scatter(xs, ys, alpha=0.5)\n","\n","# Annotate the points\n","for x, y, company in zip(xs, ys, companies):\n","    plt.annotate(company, (x, y), fontsize=5, alpha=0.75)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"5d76732f-fa8f-4f0b-80e1-151da7125bf3","metadata":{},"outputs":[],"source":["# Perform the necessary imports\n","import matplotlib.pyplot as plt\n","from scipy.stats import pearsonr\n","\n","# Assign the 0th column of grains: width\n","width = grains[:,0]\n","\n","# Assign the 1st column of grains: length\n","length = grains[:,1]\n","\n","# Scatter plot width vs length\n","plt.scatter(width, length)\n","plt.axis('equal')\n","plt.show()\n","\n","# Calculate the Pearson correlation\n","correlation, pvalue = pearsonr(width, length)\n","\n","# Display the correlation\n","print(correlation)\n"]},{"cell_type":"code","execution_count":null,"id":"bdd97fa5-5805-43fc-90b6-fa935d4743b2","metadata":{},"outputs":[],"source":["# Import PCA\n","from sklearn.decomposition import PCA\n","\n","# Create PCA instance: model\n","model = PCA()\n","\n","# Apply the fit_transform method of model to grains: pca_features\n","pca_features = model.fit_transform(grains)\n","\n","# Assign 0th column of pca_features: xs\n","xs = pca_features[:,0]\n","\n","# Assign 1st column of pca_features: ys\n","ys = pca_features[:,1]\n","\n","# Scatter plot xs vs ys\n","plt.scatter(xs, ys)\n","plt.axis('equal')\n","plt.show()\n","\n","# Calculate the Pearson correlation of xs and ys\n","correlation, pvalue = pearsonr(xs, ys)\n","\n","# Display the correlation\n","print(correlation)"]},{"cell_type":"code","execution_count":null,"id":"5f74fbb1-4c31-4e87-a466-8dee8268eb5b","metadata":{},"outputs":[],"source":["# Make a scatter plot of the untransformed points\n","plt.scatter(grains[:,0], grains[:,1])\n","\n","# Create a PCA instance: model\n","model = PCA()\n","\n","# Fit model to points\n","model.fit(grains)\n","\n","# Get the mean of the grain samples: mean\n","mean = model.mean_\n","\n","# Get the first principal component: first_pc\n","first_pc = model.components_[0]\n","\n","# Plot first_pc as an arrow, starting at mean\n","plt.arrow(mean[0], mean[1], first_pc[0], first_pc[1], color='red', width=0.01)\n","\n","# Keep axes on same scale\n","plt.axis('equal')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"5a4b7666-53a6-480d-b822-7b6d834d2deb","metadata":{},"outputs":[],"source":["# Perform the necessary imports\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import make_pipeline\n","import matplotlib.pyplot as plt\n","\n","# Create scaler: scaler\n","scaler = StandardScaler()\n","\n","# Create a PCA instance: pca\n","pca = PCA()\n","\n","# Create pipeline: pipeline\n","pipeline = make_pipeline(scaler, pca)\n","\n","# Fit the pipeline to 'samples'\n","pipeline.fit(samples)\n","\n","# Plot the explained variances\n","features = range(pca.n_components_)\n","plt.bar(features, pca.explained_variance_)\n","plt.xlabel('PCA feature')\n","plt.ylabel('variance')\n","plt.xticks(features)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"bca9571a-7452-4e20-aa3c-d7c4b843bda4","metadata":{},"outputs":[],"source":["# Import PCA\n","from sklearn.decomposition import PCA\n","\n","# Create a PCA model with 2 components: pca\n","pca = PCA(n_components=2)\n","\n","# Fit the PCA instance to the scaled samples\n","pca.fit(scaled_samples)\n","\n","# Transform the scaled samples: pca_features\n","pca_features = pca.transform(scaled_samples)\n","\n","# Print the shape of pca_features\n","print(pca_features.shape)\n"]},{"cell_type":"code","execution_count":null,"id":"0a1048bf-64f7-4a92-a208-a00c4f08ddc6","metadata":{},"outputs":[],"source":["'''In this exercise, you'll create a tf-idf word frequency array for a toy collection of documents. For this, use the TfidfVectorizer from sklearn. It transforms a list of documents into a word frequency array, which it outputs as a csr_matrix. It has fit() and transform() methods like other sklearn objects.\n","\n","You are given a list documents of toy documents about pets. Its contents have been printed in the IPython Shell.'''\n","\n","# Import TfidfVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Create a TfidfVectorizer: tfidf\n","tfidf = TfidfVectorizer() \n","\n","# Apply fit_transform to document: csr_mat\n","csr_mat = tfidf.fit_transform(documents)\n","\n","# Print result of toarray() method\n","print(csr_mat.toarray())\n","\n","# Get the words: words\n","words = tfidf.get_feature_names()\n","\n","# Print words\n","print(words)\n"]},{"cell_type":"code","execution_count":null,"id":"ac1eeebd-ca3d-42e2-a9e8-55f6d38e58e2","metadata":{},"outputs":[],"source":["# Perform the necessary imports\n","from sklearn.cluster import KMeans\n","from sklearn.pipeline import make_pipeline\n","from sklearn.decomposition import TruncatedSVD\n","\n","# Create a TruncatedSVD instance: svd\n","svd = TruncatedSVD(n_components=50)\n","\n","# Create a KMeans instance: kmeans\n","kmeans = KMeans(n_clusters=6)\n","\n","# Create a pipeline: pipeline\n","pipeline = make_pipeline(svd, kmeans)\n"]},{"cell_type":"code","execution_count":null,"id":"d6ff1d5c-fb35-425c-9097-106ec296bfbe","metadata":{},"outputs":[],"source":["# Import pandas\n","import pandas as pd\n","\n","# Fit the pipeline to articles\n","pipeline.fit(articles)\n","\n","# Calculate the cluster labels: labels\n","labels = pipeline.predict(articles)\n","\n","# Create a DataFrame aligning labels and titles: df\n","df = pd.DataFrame({'label': labels, 'article': titles})\n","\n","# Display df sorted by cluster label\n","print(df.sort_values('label'))\n"]},{"cell_type":"markdown","id":"67b5570b-2d41-4bc1-b21f-a286632e021b","metadata":{},"source":["Non-negative Matrix Factorization (NMF)"]},{"cell_type":"code","execution_count":null,"id":"8876a22b-06a9-467f-bf63-1d1bb99dd3b7","metadata":{},"outputs":[],"source":["# Import NMF\n","from sklearn.decomposition import NMF\n","\n","# Create an NMF instance: model\n","model = NMF(n_components=6)\n","\n","# Fit the model to articles\n","model.fit(articles)\n","\n","# Transform the articles: nmf_features\n","nmf_features = model.transform(articles)\n","\n","# Print the NMF features\n","print(nmf_features.round(2))\n"]},{"cell_type":"code","execution_count":null,"id":"db62f9b5-e313-4f88-b865-2d7d43b670f6","metadata":{},"outputs":[],"source":["# Import pandas\n","import pandas as pd\n","\n","# Create a pandas DataFrame: df\n","df = pd.DataFrame(nmf_features, index=titles)\n","\n","# Print the row for 'Anne Hathaway'\n","print(df.loc['Anne Hathaway'])\n","\n","# Print the row for 'Denzel Washington'\n","print(df.loc['Denzel Washington'])\n"]},{"cell_type":"code","execution_count":null,"id":"67c611bb-d9b5-4715-a063-02def8946860","metadata":{},"outputs":[],"source":["# Import pandas\n","import pandas as pd\n","\n","# Create a DataFrame: components_df\n","components_df = pd.DataFrame(model.components_, columns=words)\n","\n","# Print the shape of the DataFrame\n","print(components_df.shape)\n","\n","# Select row 3: component\n","component = components_df.iloc[3]\n","\n","# Print result of nlargest\n","print(component.nlargest())\n"]},{"cell_type":"code","execution_count":null,"id":"3af93351-1435-4b6d-a8db-1325078ae94c","metadata":{},"outputs":[],"source":["# Import pyplot\n","from matplotlib import pyplot as plt\n","\n","# Select the 0th row: digit\n","digit = samples[0,:]\n","\n","# Print digit\n","print(digit)\n","\n","# Reshape digit to a 13x8 array: bitmap\n","bitmap = digit.reshape(13,8)\n","\n","# Print bitmap\n","print(bitmap)\n","\n","# Use plt.imshow to display bitmap\n","plt.imshow(bitmap, cmap='gray', interpolation='nearest')\n","plt.colorbar()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"1e488589-ddf5-46cb-87f7-09153ad3c6a9","metadata":{},"outputs":[],"source":["# Import NMF\n","from sklearn.decomposition import NMF\n","\n","# Create an NMF model: model\n","model = NMF(n_components=7)\n","\n","# Apply fit_transform to samples: features\n","features = model.fit_transform(samples)\n","\n","# Call show_as_image on each component\n","for component in model.components_:\n","    show_as_image(component)\n","\n","# Select the 0th row of features: digit_features\n","digit_features = features[0,:]\n","\n","# Print digit_features\n","print(digit_features)"]},{"cell_type":"code","execution_count":null,"id":"3a3fd5ea-c59f-4531-a81c-cf3faed49360","metadata":{},"outputs":[],"source":["# Import PCA\n","from sklearn.decomposition import PCA\n","\n","# Create a PCA instance: model\n","model = PCA(n_components=7)\n","\n","# Apply fit_transform to samples: features\n","features = model.fit_transform(samples)\n","\n","# Call show_as_image on each component\n","for component in model.components_:\n","    show_as_image(component)\n","    "]},{"cell_type":"code","execution_count":null,"id":"27f12dcb-505a-4d23-a3e2-a4bd27efedb2","metadata":{},"outputs":[],"source":["'''Which articles are similar to 'Cristiano Ronaldo'?\n","In the video, you learned how to use NMF features and the cosine similarity to find similar articles. Apply this to your NMF model for popular Wikipedia articles, by finding the articles most similar to the article about the footballer Cristiano Ronaldo. The NMF features you obtained earlier are available as nmf_features, while titles is a list of the article titles.'''\n","\n","# Perform the necessary imports\n","import pandas as pd\n","from sklearn.preprocessing import normalize\n","\n","# Normalize the NMF features: norm_features\n","norm_features = normalize(nmf_features)\n","\n","# Create a DataFrame: df\n","df = pd.DataFrame(norm_features, index=titles)\n","\n","# Select the row corresponding to 'Cristiano Ronaldo': article\n","article = df.loc['Cristiano Ronaldo']\n","\n","# Compute the dot products: similarities\n","similarities = df.dot(article)\n","\n","# Display those with the largest cosine similarity\n","print(similarities.nlargest())"]},{"cell_type":"code","execution_count":null,"id":"e3e5b0c2-c802-4cee-b3cc-8021a6e3bc4d","metadata":{},"outputs":[],"source":["# Perform the necessary imports\n","from sklearn.decomposition import NMF\n","from sklearn.preprocessing import Normalizer, MaxAbsScaler\n","from sklearn.pipeline import make_pipeline\n","\n","# Create a MaxAbsScaler: scaler\n","scaler = MaxAbsScaler()\n","\n","# Create an NMF model: nmf\n","nmf = NMF(n_components=20)\n","\n","# Create a Normalizer: normalizer\n","normalizer = Normalizer()\n","\n","# Create a pipeline: pipeline\n","pipeline = make_pipeline(scaler, nmf, normalizer)\n","\n","# Apply fit_transform to artists: norm_features\n","norm_features = pipeline.fit_transform(artists)\n"]},{"cell_type":"code","execution_count":null,"id":"64972c5e-5047-49e4-bdb6-b27ac9ec0818","metadata":{},"outputs":[],"source":["# Import pandas\n","import pandas as pd\n","\n","# Create a DataFrame: df\n","df = pd.DataFrame(norm_features, index=artist_names)\n","\n","# Select row of 'Bruce Springsteen': artist\n","artist = df.loc['Bruce Springsteen']\n","\n","# Compute cosine similarities: similarities\n","similarities = df.dot(artist)\n","\n","# Display those with highest cosine similarity\n","print(similarities.nlargest())\n"]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
