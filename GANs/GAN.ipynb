{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GANs employ two neural networks, the Generator and the Discriminator, that are trained simultaneously through adversarial training, with the objective to create new data that is indistinguishable from real data.'''\n",
    "import torch.nn as nn\n",
    "def gen_block(in_dim, out_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_dim, out_dim),\n",
    "        nn.BatchNorm1d(out_dim),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        # Define generator block\n",
    "        self.generator = ____(\n",
    "            gen_block(in_dim, 256),\n",
    "            gen_block(256, 512),\n",
    "            gen_block(512, 1024),\n",
    "          \t# Add linear layer\n",
    "            nn.Linear(1024, out_dim),\n",
    "            # Add activation\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "      \t# Pass input through generator\n",
    "        return self.generator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_block(in_dim, out_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_dim, out_dim),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            disc_block(im_dim, 1024),\n",
    "            disc_block(1024, 512),\n",
    "            # Define last discriminator block\n",
    "            disc_block(512, 256),\n",
    "            # Add a linear layer\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward method\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Convolutional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_gen_block(in_dim, out_dim, kernel_size, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_dim, out_dim, kernel_size, stride=stride),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "class DCGenerator(nn.Module):\n",
    "    def __init__(self, in_dim, kernel_size=4, stride=2):\n",
    "        super(DCGenerator, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            dc_gen_block(in_dim, 1024, kernel_size, stride),\n",
    "            dc_gen_block(1024, 512, kernel_size, stride),\n",
    "            # Add last generator block\n",
    "            dc_gen_block(512, 256, kernel_size, stride),\n",
    "            # Add transposed convolution\n",
    "            nn.ConvTranspose2d(256, 3, kernel_size, stride=stride),\n",
    "            # Add tanh activation\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(len(x), self.in_dim, 1, 1)\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_disc_block(in_dim, out_dim, kernel_size, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_dim, out_dim, kernel_size, stride=stride),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        nn.LeakyReLU(0.2),\n",
    "    )\n",
    "\n",
    "class DCDiscriminator(nn.Module):\n",
    "    def __init__(self, kernel_size=4, stride=2):\n",
    "        super(DCDiscriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "          \t# Add first discriminator block\n",
    "            dc_disc_block(3, 512, kernel_size, stride),\n",
    "            dc_disc_block(512, 1024, kernel_size, stride),\n",
    "          \t# Add a convolution\n",
    "            nn.Conv2d(1024, 1, kernel_size, stride=stride),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through sequential block\n",
    "        x = self.disc(x)\n",
    "        return x.view(len(x), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training GANs - generator's loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_loss(gen, disc, criterion, num_images, z_dim):\n",
    "    # Define random noise\n",
    "    noise = torch.randn(num_images, z_dim)\n",
    "    # Generate fake image\n",
    "    fake = gen(noise)\n",
    "    # Get discriminator's prediction on the fake image\n",
    "    disc_pred = disc(fake)\n",
    "    # Compute generator loss\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    gen_loss = criterion(disc_pred, torch.ones_like(disc_pred))\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_loss(gen, disc, real, num_images, z_dim):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    noise = torch.randn(num_images, z_dim)\n",
    "    fake = gen(noise)\n",
    "    # Get discriminator's predictions for fake images\n",
    "    disc_pred_fake = disc(fake)\n",
    "    # Calculate the fake loss component\n",
    "    fake_loss = criterion(disc_pred_fake, torch.zeros_like(disc_pred_fake))\n",
    "    # Get discriminator's predictions for real images\n",
    "    disc_pred_real = disc(real)\n",
    "    # Calculate the real loss component\n",
    "    real_loss = criterion(disc_pred_real, torch.zeros_like(disc_pred_real))\n",
    "    disc_loss = (real_loss + fake_loss) / 2\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    for real in dataloader:\n",
    "        cur_batch_size = len(real)\n",
    "        \n",
    "        disc_opt.zero_grad()\n",
    "        # Calculate discriminator loss\n",
    "        disc_loss = disc_loss(gen, disc, real, cur_batch_size, z_dim=16)\n",
    "        # Compute gradients\n",
    "        disc_loss.backward()\n",
    "        disc_opt.step()\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        # Calculate generator loss\n",
    "        gen_loss = gen_loss(gen, disc, cur_batch_size, z_dim=16)\n",
    "        # Compute generator gradients\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        print(f\"Generator loss: {gen_loss}\")\n",
    "        print(f\"Discriminator loss: {disc_loss}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_to_generate = 5\n",
    "# Create random noise tensor\n",
    "noise = torch.randn(num_images_to_generate, 16)\n",
    "\n",
    "# Generate images\n",
    "with torch.no_grad():\n",
    "    fake = gen(noise)\n",
    "print(f\"Generated tensor shape: {fake.shape}\")\n",
    "    \n",
    "for i in range(num_images_to_generate):\n",
    "    # Slice fake to select i-th image\n",
    "    image_tensor = fake[i, :, :, :]\n",
    "    # Permute the image dimensions\n",
    "    image_tensor_permuted = image_tensor.permute(1,2,0)\n",
    "    plt.imshow(image_tensor_permuted)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FrechetInceptionDistance\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "# Instantiate FID\n",
    "fid = FrechetInceptionDistance(feature=64)\n",
    "\n",
    "# Update FID with real images\n",
    "fid.update((fake * 255).to(torch.uint8), real=False)\n",
    "fid.update((real * 255).to(torch.uint8), real=True)\n",
    "\n",
    "# Compute the metric\n",
    "fid_score = fid.compute()\n",
    "print(fid_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSThesisWorks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
