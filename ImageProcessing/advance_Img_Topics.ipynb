{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the edges with Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the canny edge detector \n",
    "from skimage.feature import canny\n",
    "\n",
    "# Convert image to grayscale\n",
    "grapefruit = color.rgb2gray(grapefruit)\n",
    "\n",
    "# Apply canny edge detector\n",
    "canny_edges = canny(grapefruit)\n",
    "\n",
    "# Show resulting image\n",
    "show_image(canny_edges, \"Edges with Canny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply canny edge detector with a sigma of 1.8\n",
    "edges_1_8 = canny(grapefruit, sigma=1.8)\n",
    "# Apply canny edge detector with a sigma of 2.2\n",
    "edges_2_2 = canny(grapefruit, sigma=2.2)\n",
    "# Show resulting images\n",
    "show_image(edges_1_8, \"Sigma of 1.8\")\n",
    "show_image(edges_2_2, \"Sigma of 2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corner matching in an image with edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the corner detector related functions and module\n",
    "from skimage.feature import corner_harris, corner_peaks\n",
    "# Convert image from RGB-3 to grayscale\n",
    "building_image_gray = color.rgb2gray(building_image)\n",
    "# Apply the detector  to measure the possible corners\n",
    "measure_image = corner_harris(building_image_gray)\n",
    "# Find the peaks of the corners using the Harris detector\n",
    "coords = corner_peaks(corner_harris(building_image_gray), min_distance=20, threshold_rel=0.02)\n",
    "# Show original and resulting image with corners detected\n",
    "show_image(building_image, \"Original\")\n",
    "show_image_with_corners(building_image, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the peaks with a min distance of 10 pixels\n",
    "coords_w_min_10 = corner_peaks(measure_image, min_distance=10, threshold_rel=0.02)\n",
    "print(\"With a min_distance set to 10, we detect a total\", len(coords_w_min_10), \"corners in the image.\")\n",
    "\n",
    "# Find the peaks with a min distance of 60 pixels\n",
    "coords_w_min_60 = corner_peaks(measure_image, min_distance=60, threshold_rel=0.02)\n",
    "print(\"With a min_distance set to 60, we detect a total\", len(coords_w_min_60), \"corners in the image.\")\n",
    "\n",
    "# Show original and resulting image with corners detected\n",
    "show_image_with_corners(building_image, coords_w_min_10, \"Corners detected with 10 px of min_distance\")\n",
    "show_image_with_corners(building_image, coords_w_min_60, \"Corners detected with 60 px of min_distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FACE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The Cascade of classifiers class from feature module has already been imported, as well as the show_detected_face() function which is used to display the face marked in the image and crop it so it can be shown separately.\n",
    "    \n",
    "'''\n",
    "def show_detected_face(result, detected, title=\"Face image\"):\n",
    "    plt.figure()\n",
    "    plt.imshow(result)\n",
    "    img_desc = plt.gca()\n",
    "    plt.set_cmap('gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "    for patch in detected:\n",
    "        \n",
    "        img_desc.add_patch(\n",
    "            patches.Rectangle(\n",
    "                (patch['c'], patch['r']),\n",
    "                patch['width'],\n",
    "                patch['height'],\n",
    "                fill=False,\n",
    "                color='r',\n",
    "                linewidth=2)\n",
    "        )\n",
    "        crop_face(result, detected)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained file from data\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "# Initialize the detector cascade\n",
    "detector = Cascade(trained_file)\n",
    "# Detect faces with min and max size of searching window\n",
    "detected = detector.detect_multi_scale(img = night_image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10,10),\n",
    "                                       max_size=(200,200))\n",
    "\n",
    "# Show the detected faces\n",
    "show_detected_face(night_image, detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained file from data\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "# Initialize the detector cascade\n",
    "detector = Cascade(trained_file)\n",
    "# Detect faces with scale factor to 1.2 and step ratio to 1\n",
    "detected = detector.detect_multi_scale(img=friends_image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10, 10),\n",
    "                                       max_size=(200, 200))\n",
    "# Show the detected faces\n",
    "show_detected_face(friends_image, detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The Cascade class, the slic() function from segmentation module, and the show_detected_face() function for visualization have already been imported. The detector is already initialized and ready to use as detector.'''\n",
    "# Obtain the segmentation with default 100 regions\n",
    "segments = slic(profile_image, n_segments=100)\n",
    "\n",
    "# Obtain segmented image using label2rgb\n",
    "segmented_image = label2rgb(segments, profile_image, kind='avg')\n",
    "\n",
    "# Detect the faces with multi scale method\n",
    "detected = detector.detect_multi_scale(img=segmented_image, \n",
    "                                       scale_factor=1.2, \n",
    "                                       step_ratio=1, \n",
    "                                       min_size=(10, 10), max_size=(1000, 1000))\n",
    "\n",
    "# Show the detected faces\n",
    "show_detected_face(segmented_image, detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Privacy protection using gaussian filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the faces\n",
    "detected = detector.detect_multi_scale(img=group_image, \n",
    "                                       scale_factor=1.2, step_ratio=1, \n",
    "                                       min_size=(10,10), max_size=(100, 100))\n",
    "# For each detected face\n",
    "for d in detected:  \n",
    "    # Obtain the face rectangle from detected coordinates\n",
    "    face = getFaceRectangle(d)\n",
    "    \n",
    "    # Apply gaussian filter to extracted face\n",
    "    blurred_face = gaussian(face, multichannel=True, sigma = 8)\n",
    "    \n",
    "    # Merge this blurry face to our final image and show it\n",
    "    resulting_image = mergeBlurryFace(group_image, blurred_face) \n",
    "show_image(resulting_image, \"Blurred faces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from skimage.restoration import denoise_tv_chambolle, inpaint\n",
    "from skimage import transform\n",
    "\n",
    "# Transform the image so it's not rotated\n",
    "upright_img = rotate(damaged_image, 20)\n",
    "\n",
    "# Remove noise from the image, using the chambolle method\n",
    "upright_img_without_noise = denoise_tv_chambolle(upright_img,weight=0.1, multichannel=True)\n",
    "\n",
    "# Reconstruct the image missing parts\n",
    "mask = get_mask(upright_img)\n",
    "result = inpaint.inpaint_biharmonic(upright_img_without_noise, mask, multichannel=True)\n",
    "\n",
    "show_image(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSThesisWorks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
