{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "# Compose transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128)),\n",
    "])\n",
    "\n",
    "# Create Dataset using ImageFolder\n",
    "dataset_train = ImageFolder(\n",
    "    'clouds_train',\n",
    "    transform=train_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA AUGMENTATION\n",
    "1. Using data augmentation allows the model to learn from more examples\n",
    "2. Using data augmentation increases the diversity of the training data\n",
    "3. Data augmentation makes the model more robust to variations and distortions commonly found in real-world images\n",
    "4. Data augmentation reduces the risk of overfitting as the model learns to ignore the random transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    # Add horizontal flip and rotation\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((128, 128)),\n",
    "])\n",
    "\n",
    "dataset_train = ImageFolder(\n",
    "  \"clouds_train\",\n",
    "  transform=train_transforms,\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "  dataset_train, shuffle=True, batch_size=1\n",
    ")\n",
    "\n",
    "image, label = next(iter(dataloader_train))\n",
    "# Reshape the image tensor\n",
    "image = image.squeeze().permute(1, 2, 0) \n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Define feature extractor\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        # Define classifier\n",
    "        self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "    \n",
    "    def forward(self, x):  \n",
    "        # Pass input through feature extractor and classifier\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "net = Net(num_classes=7)\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    # Iterate over training batches\n",
    "    for images, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader_train)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Image Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metric_precision = Precision(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "metric_recall = Recall(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "        metric_recall(preds, labels)\n",
    "\n",
    "precision = metric_precision.compute()\n",
    "recall = metric_recall.compute()\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "metric_precision = Precision(task=\"multiclass\", num_classes=7, average=None)\n",
    "metric_recall = Recall(task=\"multiclass\", num_classes=7, average=None)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "        metric_recall(preds, labels)\n",
    "\n",
    "precision = metric_precision.compute()\n",
    "recall = metric_recall.compute()\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define precision metric\n",
    "metric_precision = Precision(\n",
    "    task=\"multiclass\", num_classes=7, average=None\n",
    ")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "precision = metric_precision.compute()\n",
    "\n",
    "# Get precision per class\n",
    "precision_per_class = {\n",
    "    k: precision[v].item()\n",
    "    for k, v \n",
    "    in dataset_test.class_to_idx.items()\n",
    "}\n",
    "print(precision_per_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSThesisWorks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
